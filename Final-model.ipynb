{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'dataset-final - 3000.csv')\n",
    "df_copy=pd.read_csv(r'dataset-final - 3000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aycha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aycha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aycha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Prétraitement textuel avec NLTK**\n",
    "Certains chiffres se rapportent à des catégories spécifiques (âge, quantité, année, etc.), On  les transformer en catégories spécifiques. Car le modele ne peut pas lire les chiffres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Vérifie si le texte est une chaîne\n",
    "        # Remplacer les chiffres par des catégories basées sur des expressions régulières\n",
    "        text = re.sub(r'\\b\\d{1,2} ans\\b', 'AGE', text)  # Remplacer les âges\n",
    "        text = re.sub(r'\\b\\d{4}\\b', 'YEAR', text)  # Remplacer les années\n",
    "        text = re.sub(r'\\b\\d+\\s?(kg|g|lbs|ounces|items|people|years|dollars|euro|hour|minutes)\\b', 'QUANTITE', text)  # Remplacer les quantités\n",
    "\n",
    "        # Tokenisation, Lemmatisation et suppression des stopwords\n",
    "        tokens = word_tokenize(text.lower())  # Tokenisation\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum()]  # Lemmatisation\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Suppression des stopwords\n",
    "        \n",
    "        return \" \".join(tokens)\n",
    "    return \"\"  # Retourne une chaîne vide si le texte n'est pas valide\n",
    "\n",
    "\n",
    "df_copy[\"SYNOPSIS\"] = df_copy[\"SYNOPSIS\"].apply(preprocess_text)\n",
    "df_copy[\"REVIEWS\"] = df_copy[\"REVIEWS\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer la colonne GENRES en colonnes binaires, où chaque genre sera une nouvelle colonne contenant des valeurs 1 (présence du genre) ou 0 (absence du genre) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['GENRES'] = df_copy['GENRES'].apply(lambda x: x.split('; ') if isinstance(x, str) else [])\n",
    "\n",
    "# Créer une liste de tous les genres uniques présents dans la colonne GENRES\n",
    "all_genres = set([genre for sublist in df_copy['GENRES'] for genre in sublist])\n",
    "\n",
    "# Créer une nouvelle colonne pour chaque genre avec 1 ou 0 en fonction de la présence du genre\n",
    "for genre in all_genres:\n",
    "    df_copy[f'genre_{genre}'] = df_copy['GENRES'].apply(lambda x: 1 if genre in x else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'MOVIE_NAME', 'REVIEWS', 'SYNOPSIS', 'YEAR', 'CAST',\n",
       "       'DURATION_MIN', 'GENRES', 'PRODUCERS', 'RATING_SUR_5',\n",
       "       'MAJORITY_SENTIMENT', 'MOST_FREQUENT_SENTIMENT', 'Rating_Category',\n",
       "       'genre_War', 'genre_LGBTQ+', 'genre_Fantasy', 'genre_History',\n",
       "       'genre_Holiday', 'genre_Documentary', 'genre_Mystery', 'genre_Music',\n",
       "       'genre_Action', 'genre_Kids & Family', 'genre_Horror', 'genre_Anime',\n",
       "       'genre_Musical', 'genre_Drama', 'genre_TV Movie', 'genre_Biography',\n",
       "       'genre_Western', 'genre_Animation', 'genre_Sci-Fi', 'genre_Comedy',\n",
       "       'genre_Thriller', 'genre_Adventure', 'genre_Sports', 'genre_Family',\n",
       "       'genre_Crime', 'genre_Science Fiction', 'genre_Mystery & Thriller',\n",
       "       'genre_Romance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir les acteurs les plus frequents dans les films les mieux notés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assurer que chaque valeur dans 'CAST' est une liste\n",
    "df_copy['CAST'] = df_copy['CAST'].apply(lambda x: x.split(', ') if isinstance(x, str) else [])\n",
    "# Filtrer les entrées non pertinentes dans la colonne 'CAST' ('Show All…', 'Indisponible', '')\n",
    "df_copy['CAST'] = df_copy['CAST'].apply(lambda x: [actor for actor in x if actor not in ['Show All…', 'Indisponible', '']])\n",
    "\n",
    "# Filtrer les films avec une note supérieure à 3.5\n",
    "good_movies = df_copy[df_copy['RATING_SUR_5'] >= 3.5]\n",
    "\n",
    "# Aplatir la liste des acteurs pour les films ayant une note > 3.5\n",
    "all_casts = [actor for sublist in good_movies['CAST'] for actor in sublist]\n",
    "\n",
    "# Compter la fréquence de chaque acteur\n",
    "from collections import Counter\n",
    "cast_counts = Counter(all_casts)\n",
    "\n",
    "# Sélectionner les 10 acteurs les plus populaires\n",
    "popular_casts = [actor for actor, _ in cast_counts.most_common(10)]\n",
    "\n",
    "# Créer une nouvelle colonne pour chaque acteur populaire\n",
    "for actor in popular_casts:\n",
    "    df_copy[f'ACTEUR_{actor}'] = df_copy['CAST'].apply(lambda x: 1 if actor in x else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'MOVIE_NAME', 'REVIEWS', 'SYNOPSIS', 'YEAR', 'CAST',\n",
       "       'DURATION_MIN', 'GENRES', 'PRODUCERS', 'RATING_SUR_5',\n",
       "       'MAJORITY_SENTIMENT', 'MOST_FREQUENT_SENTIMENT', 'Rating_Category',\n",
       "       'genre_War', 'genre_LGBTQ+', 'genre_Fantasy', 'genre_History',\n",
       "       'genre_Holiday', 'genre_Documentary', 'genre_Mystery', 'genre_Music',\n",
       "       'genre_Action', 'genre_Kids & Family', 'genre_Horror', 'genre_Anime',\n",
       "       'genre_Musical', 'genre_Drama', 'genre_TV Movie', 'genre_Biography',\n",
       "       'genre_Western', 'genre_Animation', 'genre_Sci-Fi', 'genre_Comedy',\n",
       "       'genre_Thriller', 'genre_Adventure', 'genre_Sports', 'genre_Family',\n",
       "       'genre_Crime', 'genre_Science Fiction', 'genre_Mystery & Thriller',\n",
       "       'genre_Romance', 'ACTEUR_Tom Cruise', 'ACTEUR_Samuel L. Jackson',\n",
       "       'ACTEUR_Mickie McGowan', 'ACTEUR_Ving Rhames', 'ACTEUR_Brad Pitt',\n",
       "       'ACTEUR_Jr.', 'ACTEUR_Sherry Lynn', 'ACTEUR_Robert De Niro',\n",
       "       'ACTEUR_Ralph Fiennes', 'ACTEUR_Jack Angel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meme chose pour les producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assurez-vous que la colonne 'PRODUCERS' contient une liste\n",
    "df_copy['PRODUCERS'] = df_copy['PRODUCERS'].apply(lambda x: x.split('; ') if isinstance(x, str) else [])\n",
    "\n",
    "# Filtrer les entrées non pertinentes dans la colonne 'PRODUCERS' ('Show All…', 'Indisponible', '')\n",
    "df_copy['PRODUCERS'] = df_copy['PRODUCERS'].apply(lambda x: [producer for producer in x if producer not in ['Show All…', 'Indisponible', '']])\n",
    "\n",
    "# Filtrer les films avec une note supérieure à 3.5\n",
    "good_movies = df_copy[df_copy['RATING_SUR_5'] >= 3.5]\n",
    "\n",
    "# Aplatir la liste des producteurs pour les films ayant une note > 3.5\n",
    "all_producers = [producer for sublist in good_movies['PRODUCERS'] for producer in sublist]\n",
    "\n",
    "# Compter la fréquence de chaque producteur\n",
    "producer_counts = Counter(all_producers)\n",
    "\n",
    "# Sélectionner les 10 producteurs les plus populaires\n",
    "popular_producers = [producer for producer, _ in producer_counts.most_common(10)]\n",
    "\n",
    "# Créer une nouvelle colonne pour chaque producteur populaire\n",
    "for producer in popular_producers:\n",
    "    df_copy[f'PRODUCER_{producer}'] = df_copy['PRODUCERS'].apply(lambda x: 1 if producer in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'MOVIE_NAME', 'REVIEWS', 'SYNOPSIS', 'YEAR', 'CAST',\n",
       "       'DURATION_MIN', 'GENRES', 'PRODUCERS', 'RATING_SUR_5',\n",
       "       'MAJORITY_SENTIMENT', 'MOST_FREQUENT_SENTIMENT', 'Rating_Category',\n",
       "       'genre_War', 'genre_LGBTQ+', 'genre_Fantasy', 'genre_History',\n",
       "       'genre_Holiday', 'genre_Documentary', 'genre_Mystery', 'genre_Music',\n",
       "       'genre_Action', 'genre_Kids & Family', 'genre_Horror', 'genre_Anime',\n",
       "       'genre_Musical', 'genre_Drama', 'genre_TV Movie', 'genre_Biography',\n",
       "       'genre_Western', 'genre_Animation', 'genre_Sci-Fi', 'genre_Comedy',\n",
       "       'genre_Thriller', 'genre_Adventure', 'genre_Sports', 'genre_Family',\n",
       "       'genre_Crime', 'genre_Science Fiction', 'genre_Mystery & Thriller',\n",
       "       'genre_Romance', 'ACTEUR_Tom Cruise', 'ACTEUR_Samuel L. Jackson',\n",
       "       'ACTEUR_Mickie McGowan', 'ACTEUR_Ving Rhames', 'ACTEUR_Brad Pitt',\n",
       "       'ACTEUR_Jr.', 'ACTEUR_Sherry Lynn', 'ACTEUR_Robert De Niro',\n",
       "       'ACTEUR_Ralph Fiennes', 'ACTEUR_Jack Angel', 'PRODUCER_Scott Rudin',\n",
       "       'PRODUCER_Ethan Coen', 'PRODUCER_Tim Bevan', 'PRODUCER_Eric Fellner',\n",
       "       'PRODUCER_David Heyman', 'PRODUCER_Arnon Milchan',\n",
       "       'PRODUCER_Kevin Feige', 'PRODUCER_Kathleen Kennedy',\n",
       "       'PRODUCER_Frank Marshall', 'PRODUCER_Wes Anderson'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['DURATION_MIN'] = df_copy['DURATION_MIN'].apply(pd.to_numeric, errors='coerce')  # Assurez-vous qu'il s'agit de données numériques\n",
    "\n",
    "# Normalisation de DURATION\n",
    "scaler = StandardScaler()\n",
    "df_copy['DURATION_MIN'] = scaler.fit_transform(df_copy[['DURATION_MIN']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorisation des colonnes textuelles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_rating = data[data['RATING_SUR_5'].isna()]  # Films sans 'RATING'\n",
    "data = data.dropna(subset=['RATING_SUR_5']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['GENRES'] = data['GENRES'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n",
    "data['CAST'] = data['CAST'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n",
    "data['PRODUCERS'] = data['PRODUCERS'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(\"\")\n",
    "\n",
    "# Vectorisation des colonnes textuelles\n",
    "vectorizer_synopsis = TfidfVectorizer(max_features=800)\n",
    "vectorizer_reviews = TfidfVectorizer(max_features=1000)\n",
    "vectorizer_genres = TfidfVectorizer(max_features=500)\n",
    "vectorizer_cast = TfidfVectorizer(max_features=500)\n",
    "vectorizer_producers = TfidfVectorizer(max_features=500)\n",
    "\n",
    "# Transformation des colonnes textuelles en caractéristiques TF-IDF\n",
    "synopsis_features = vectorizer_synopsis.fit_transform(data['SYNOPSIS']).toarray()\n",
    "reviews_features = vectorizer_reviews.fit_transform(data['REVIEWS']).toarray()\n",
    "genre_features = vectorizer_genres.fit_transform(data['GENRES']).toarray()\n",
    "cast_features = vectorizer_cast.fit_transform(data['CAST']).toarray()\n",
    "producers_features = vectorizer_producers.fit_transform(data['PRODUCERS']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les caractéristiques textuelles\n",
    "textual_features = np.hstack([synopsis_features, reviews_features, genre_features, cast_features, producers_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0   -0.444013\n",
      "1    0.956833\n",
      "2   -0.163844\n",
      "3    0.793401\n",
      "4   -0.187191\n",
      "Name: DURATION_MIN, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Vérifier le type des données de la colonne DURATION_MIN\n",
    "print(data['DURATION_MIN'].dtype)\n",
    "\n",
    "# Vérifier si la colonne contient des chaînes de caractères\n",
    "print(data['DURATION_MIN'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitement des colonnes numériques\n",
    "# Convertir la colonne 'DURATION_MIN' en type numérique, en remplaçant les valeurs non numériques par NaN\n",
    "data['DURATION_MIN'] = pd.to_numeric(data['DURATION_MIN'], errors='coerce')\n",
    "data['DURATION_MIN'] = data['DURATION_MIN'].fillna(data['DURATION_MIN'].mean())\n",
    "numerical_columns = ['DURATION_MIN']\n",
    "numerical_data = data[numerical_columns].values\n",
    "data[numerical_columns] = data[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "scaler = StandardScaler()\n",
    "numerical_features = scaler.fit_transform(numerical_data)  # Normalisation des colonnes numériques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes binaires/one-hot (les genres , acteurs et producteurs déjà sous forme binaire)\n",
    "binary_columns = [col for col in data.columns if col.startswith('genre_') or col.startswith('ACTEUR_') or col.startswith('PRODUCER_')]\n",
    "binary_data = data[binary_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_columns = ['MOST_FREQUENT_SENTIMENT', 'Rating_Category']\n",
    "encoder = OneHotEncoder()\n",
    "categorical_data = encoder.fit_transform(data[categorical_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([textual_features, numerical_features, binary_data, categorical_data.toarray()])\n",
    "y = data['RATING_SUR_5']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de validation croisée par modèle :\n",
      "Linear Regression: 0.7980\n",
      "Random Forest Regressor: 0.2167\n",
      "Support Vector Regressor: 0.2369\n",
      "HistGradientBoosting Regressor: 0.2152\n",
      "\n",
      "Le meilleur modèle est : HistGradientBoosting Regressor\n",
      "\n",
      "Métriques de régression :\n",
      "Mean Absolute Error (MAE) : 0.2198\n",
      "Mean Squared Error (MSE) : 0.0997\n",
      "Root Mean Squared Error (RMSE) : 0.3158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Ajouter HistGradientBoostingRegressor à la liste des modèles\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(),\n",
    "    'Support Vector Regressor': SVR(),\n",
    "    'HistGradientBoosting Regressor': HistGradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Évaluation des modèles avec validation croisée (scoring : 'neg_mean_absolute_error' pour la régression)\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Validation croisée (ici 5-fold)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "    results[name] = -cv_scores.mean()  # Négatif pour avoir des valeurs positives\n",
    "\n",
    "# Affichage des résultats de validation croisée\n",
    "print(\"Scores de validation croisée par modèle :\")\n",
    "for name, score in results.items():\n",
    "    print(f\"{name}: {score:.4f}\")\n",
    "\n",
    "# Choisir le meilleur modèle\n",
    "best_model_name = min(results, key=results.get)  # Minimiser l'erreur\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nLe meilleur modèle est : {best_model_name}\")\n",
    "\n",
    "# Entraîner le meilleur modèle sur l'ensemble d'entraînement\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcul des métriques de performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"\\nMétriques de régression :\")\n",
    "print(f\"Mean Absolute Error (MAE) : {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE) : {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) : {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé sous C:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\final\\model\\best_model_0.09.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Chemin pour sauvegarder le modèle\n",
    "model_path = r\"C:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\final\\model\\best_model_0.09.pkl\"\n",
    "\n",
    "# Sauvegarder le modèle avec joblib\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"Modèle sauvegardé sous {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres :  {'learning_rate': 0.1, 'max_depth': 7, 'max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(HistGradientBoostingRegressor(), param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Meilleurs hyperparamètres : \", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métriques de régression :\n",
      "Mean Absolute Error (MAE) : 0.2211\n",
      "Mean Squared Error (MSE) : 0.0994\n",
      "Root Mean Squared Error (RMSE) : 0.3154\n",
      "R² Score: 0.8484\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# Initialisation du modèle avec les meilleurs hyperparamètres\n",
    "model = HistGradientBoostingRegressor(\n",
    "    learning_rate=0.1, \n",
    "    max_depth=7, \n",
    "    max_iter=100\n",
    ")\n",
    "\n",
    "# Entraînement du modèle sur l'ensemble d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcul des métriques de performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "# Affichage des métriques\n",
    "print(\"\\nMétriques de régression :\")\n",
    "print(f\"Mean Absolute Error (MAE) : {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE) : {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) : {rmse:.4f}\")\n",
    "print(f'R² Score: {r2:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_critic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
