{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aycha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aycha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset-final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOVIE_NAME</th>\n",
       "      <th>SYNOPSIS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CAST</th>\n",
       "      <th>GENRES</th>\n",
       "      <th>PRODUCERS</th>\n",
       "      <th>REVIEWS</th>\n",
       "      <th>DURATION_MIN</th>\n",
       "      <th>RATING_SUR_5</th>\n",
       "      <th>MAJORITY_SENTIMENT</th>\n",
       "      <th>MOST_FREQUENT_SENTIMENT</th>\n",
       "      <th>Rating_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wicked</td>\n",
       "      <td>A cul-de-sac in an oppressive suburb becomes a...</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Julia Stiles, William R. Moses, Patrick Muldoo...</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>Frank Beddor; Greg Steinberg</td>\n",
       "      <td>['one unhinged viewing experience life', 'dont...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>['neutral', 'positive', 'neutral', 'neutral', ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gladiator-ii</td>\n",
       "      <td>Years after witnessing the death of the revere...</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Paul Mescal, Denzel Washington, Pedro Pascal, ...</td>\n",
       "      <td>Drama; Action; Adventure</td>\n",
       "      <td>Michael A. Pruss; Winston Azzopardi; David Fra...</td>\n",
       "      <td>['review may contain spoiler handle truth', 'c...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>['positive', 'neutral', 'neutral', 'negative',...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moana-2</td>\n",
       "      <td>After receiving an unexpected call from her wa...</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Auliʻi Cravalho, Dwayne Johnson, Hualālai Chun...</td>\n",
       "      <td>Comedy; Animation; Adventure; Family</td>\n",
       "      <td>Christina Chen; Yvett Merino Flores</td>\n",
       "      <td>['water looked worse original', 'schaffrillas ...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.87</td>\n",
       "      <td>['negative', 'positive', 'positive', 'neutral'...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the-substance</td>\n",
       "      <td>A fading celebrity decides to use a black mark...</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Demi Moore, Margaret Qualley, Dennis Quaid, Ed...</td>\n",
       "      <td>Horror; Science Fiction</td>\n",
       "      <td>Coralie Fargeat; Eric Fellner; Tim Bevan</td>\n",
       "      <td>['mama girl inside', 'review may contain spoil...</td>\n",
       "      <td>141.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>['neutral', 'positive', 'positive', 'neutral',...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>our-little-secret</td>\n",
       "      <td>After discovering their significant others are...</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Lindsay Lohan, Ian Harding, Kristin Chenoweth,...</td>\n",
       "      <td>Drama; Romance; Comedy</td>\n",
       "      <td>Mike Elliott; Lisa Gooding</td>\n",
       "      <td>['dating much younger woman close enough welco...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.36</td>\n",
       "      <td>['positive', 'negative', 'neutral', 'positive'...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>18 to Party</td>\n",
       "      <td>Teens grapple with a spate of recent suicides,...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jeff Roda (Director), Alivia Clark (Amy), Tann...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['tim cogshell loved angsty little period dram...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>1945</td>\n",
       "      <td>A village is forced to face up to its ill-gott...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Ferenc Török (Director), Péter Rudolf (Szentes...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['leslie felperin sombre accomplished somewhat...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>1985</td>\n",
       "      <td>When an adventurous teen discovers a secret ma...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Kang Vang (Director), Chang Yang (Billy aka Be...</td>\n",
       "      <td>Comedy; Drama; Adventure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['neutral']</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>1992</td>\n",
       "      <td>Martin is 17 and spends all day recording ever...</td>\n",
       "      <td>30m</td>\n",
       "      <td>Anthony Doncque (Director), Mathieu Dessertine...</td>\n",
       "      <td>Comedy; Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['neutral']</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>1BR</td>\n",
       "      <td>New to Los Angeles, a woman moves into a seemi...</td>\n",
       "      <td>2019</td>\n",
       "      <td>David Marmor (Director), Nicole Brydon Bloom (...</td>\n",
       "      <td>Mystery &amp; Thriller; Horror; Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['becca james 1brs unique timeline paired palp...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2518 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             MOVIE_NAME                                           SYNOPSIS  \\\n",
       "0                wicked  A cul-de-sac in an oppressive suburb becomes a...   \n",
       "1          gladiator-ii  Years after witnessing the death of the revere...   \n",
       "2               moana-2  After receiving an unexpected call from her wa...   \n",
       "3         the-substance  A fading celebrity decides to use a black mark...   \n",
       "4     our-little-secret  After discovering their significant others are...   \n",
       "...                 ...                                                ...   \n",
       "2513        18 to Party  Teens grapple with a spate of recent suicides,...   \n",
       "2514               1945  A village is forced to face up to its ill-gott...   \n",
       "2515               1985  When an adventurous teen discovers a secret ma...   \n",
       "2516               1992  Martin is 17 and spends all day recording ever...   \n",
       "2517                1BR  New to Los Angeles, a woman moves into a seemi...   \n",
       "\n",
       "        YEAR                                               CAST  \\\n",
       "0     1998.0  Julia Stiles, William R. Moses, Patrick Muldoo...   \n",
       "1     2024.0  Paul Mescal, Denzel Washington, Pedro Pascal, ...   \n",
       "2     2024.0  Auliʻi Cravalho, Dwayne Johnson, Hualālai Chun...   \n",
       "3     2024.0  Demi Moore, Margaret Qualley, Dennis Quaid, Ed...   \n",
       "4     2024.0  Lindsay Lohan, Ian Harding, Kristin Chenoweth,...   \n",
       "...      ...                                                ...   \n",
       "2513    2020  Jeff Roda (Director), Alivia Clark (Amy), Tann...   \n",
       "2514    2017  Ferenc Török (Director), Péter Rudolf (Szentes...   \n",
       "2515    2016  Kang Vang (Director), Chang Yang (Billy aka Be...   \n",
       "2516     30m  Anthony Doncque (Director), Mathieu Dessertine...   \n",
       "2517    2019  David Marmor (Director), Nicole Brydon Bloom (...   \n",
       "\n",
       "                                    GENRES  \\\n",
       "0                                 Thriller   \n",
       "1                 Drama; Action; Adventure   \n",
       "2     Comedy; Animation; Adventure; Family   \n",
       "3                  Horror; Science Fiction   \n",
       "4                   Drama; Romance; Comedy   \n",
       "...                                    ...   \n",
       "2513                                Comedy   \n",
       "2514                                 Drama   \n",
       "2515              Comedy; Drama; Adventure   \n",
       "2516                         Comedy; Drama   \n",
       "2517     Mystery & Thriller; Horror; Drama   \n",
       "\n",
       "                                              PRODUCERS  \\\n",
       "0                          Frank Beddor; Greg Steinberg   \n",
       "1     Michael A. Pruss; Winston Azzopardi; David Fra...   \n",
       "2                   Christina Chen; Yvett Merino Flores   \n",
       "3              Coralie Fargeat; Eric Fellner; Tim Bevan   \n",
       "4                            Mike Elliott; Lisa Gooding   \n",
       "...                                                 ...   \n",
       "2513                                                NaN   \n",
       "2514                                                NaN   \n",
       "2515                                                NaN   \n",
       "2516                                                NaN   \n",
       "2517                                                NaN   \n",
       "\n",
       "                                                REVIEWS  DURATION_MIN  \\\n",
       "0     ['one unhinged viewing experience life', 'dont...          88.0   \n",
       "1     ['review may contain spoiler handle truth', 'c...         148.0   \n",
       "2     ['water looked worse original', 'schaffrillas ...         100.0   \n",
       "3     ['mama girl inside', 'review may contain spoil...         141.0   \n",
       "4     ['dating much younger woman close enough welco...          99.0   \n",
       "...                                                 ...           ...   \n",
       "2513  ['tim cogshell loved angsty little period dram...          80.0   \n",
       "2514  ['leslie felperin sombre accomplished somewhat...          91.0   \n",
       "2515                                               ['']         114.0   \n",
       "2516                                               ['']           NaN   \n",
       "2517  ['becca james 1brs unique timeline paired palp...          90.0   \n",
       "\n",
       "      RATING_SUR_5                                 MAJORITY_SENTIMENT  \\\n",
       "0             2.64  ['neutral', 'positive', 'neutral', 'neutral', ...   \n",
       "1             3.37  ['positive', 'neutral', 'neutral', 'negative',...   \n",
       "2             2.87  ['negative', 'positive', 'positive', 'neutral'...   \n",
       "3             3.85  ['neutral', 'positive', 'positive', 'neutral',...   \n",
       "4             2.36  ['positive', 'negative', 'neutral', 'positive'...   \n",
       "...            ...                                                ...   \n",
       "2513           NaN                                       ['positive']   \n",
       "2514           NaN                                       ['positive']   \n",
       "2515           NaN                                        ['neutral']   \n",
       "2516           NaN                                        ['neutral']   \n",
       "2517           NaN                                       ['positive']   \n",
       "\n",
       "     MOST_FREQUENT_SENTIMENT Rating_Category  \n",
       "0                   positive        Negative  \n",
       "1                    neutral         Neutral  \n",
       "2                   positive        Negative  \n",
       "3                   positive        Positive  \n",
       "4                   positive        Negative  \n",
       "...                      ...             ...  \n",
       "2513                positive        Negative  \n",
       "2514                positive        Negative  \n",
       "2515                 neutral        Negative  \n",
       "2516                 neutral        Negative  \n",
       "2517                positive        Negative  \n",
       "\n",
       "[2518 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les colonnes pertinentes en une seule colonne de texte\n",
    "df['Combined_Text'] = df['REVIEWS'] + \"/\" + df['SYNOPSIS'] + \"/\" + df['GENRES'] + \"/\" + df['CAST'] + \"/\" + df['PRODUCERS'].fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Combined_Text'] = df['Combined_Text'].str.replace(r'/+', '/', regex=True).str.strip('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    tokens = word_tokenize(text.lower())  # Tokenisation et mise en minuscule\n",
    "    tokens = [word for word in tokens if word.isalnum()]  # Supprimer la ponctuation\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Supprimer les stopwords\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['Processed_Text'] = df['Combined_Text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Normalized_Duration'] = df['DURATION_MIN'] / df['DURATION_MIN'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=10000)\n",
    "X_text = vectorizer.fit_transform(df['Processed_Text'])\n",
    "\n",
    "# Ajouter les colonnes numériques\n",
    "numeric_features = df[['Normalized_Duration']].fillna(0)\n",
    "X = hstack([X_text, numeric_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Rating_Category'].map({'Positive': 2, 'Neutral': 1, 'Negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rééquilibrer les classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "grid_search = GridSearchCV(SVC(), param_grid_svm, cv=3, scoring='f1_macro')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters for SVM:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "        \"Naive Bayes\": MultinomialNB(),\n",
    "        \"SVM\": SVC(kernel='linear', class_weight='balanced',C=1, probability=True),\n",
    "        \"XGBoost\": XGBClassifier(scale_pos_weight=1, use_label_encoder=False),\n",
    "        \"Neural Network\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=300)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive'])\n",
    "        \n",
    "        results[name] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"classification_report\": report\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{name} Results:\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"\\nClassification Report:\\n{report}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Results:\n",
      "Accuracy: 0.6957671957671958\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.67      0.71      0.69       102\n",
      "     Neutral       0.58      0.38      0.46        92\n",
      "    Positive       0.74      0.85      0.79       184\n",
      "\n",
      "    accuracy                           0.70       378\n",
      "   macro avg       0.67      0.64      0.65       378\n",
      "weighted avg       0.68      0.70      0.68       378\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.6587301587301587\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.82      0.60      0.69       102\n",
      "     Neutral       0.86      0.07      0.12        92\n",
      "    Positive       0.61      0.99      0.76       184\n",
      "\n",
      "    accuracy                           0.66       378\n",
      "   macro avg       0.76      0.55      0.52       378\n",
      "weighted avg       0.73      0.66      0.58       378\n",
      "\n",
      "\n",
      "Training Naive Bayes...\n",
      "\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.5740740740740741\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.32      0.49       102\n",
      "     Neutral       0.00      0.00      0.00        92\n",
      "    Positive       0.53      1.00      0.70       184\n",
      "\n",
      "    accuracy                           0.57       378\n",
      "   macro avg       0.50      0.44      0.39       378\n",
      "weighted avg       0.52      0.57      0.47       378\n",
      "\n",
      "\n",
      "Training SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Results:\n",
      "Accuracy: 0.6851851851851852\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.64      0.73      0.68       102\n",
      "     Neutral       0.54      0.35      0.42        92\n",
      "    Positive       0.75      0.83      0.79       184\n",
      "\n",
      "    accuracy                           0.69       378\n",
      "   macro avg       0.65      0.63      0.63       378\n",
      "weighted avg       0.67      0.69      0.67       378\n",
      "\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:06:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Results:\n",
      "Accuracy: 0.6931216931216931\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.72      0.78       102\n",
      "     Neutral       0.55      0.20      0.29        92\n",
      "    Positive       0.66      0.93      0.77       184\n",
      "\n",
      "    accuracy                           0.69       378\n",
      "   macro avg       0.69      0.61      0.61       378\n",
      "weighted avg       0.68      0.69      0.66       378\n",
      "\n",
      "\n",
      "Training Neural Network...\n",
      "\n",
      "Neural Network Results:\n",
      "Accuracy: 0.6640211640211641\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.70      0.58      0.63       102\n",
      "     Neutral       0.53      0.23      0.32        92\n",
      "    Positive       0.67      0.93      0.78       184\n",
      "\n",
      "    accuracy                           0.66       378\n",
      "   macro avg       0.63      0.58      0.58       378\n",
      "weighted avg       0.65      0.66      0.63       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Results:\n",
      "Accuracy: 0.6772486772486772\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.67      0.65      0.66       102\n",
      "     Neutral       0.54      0.29      0.38        92\n",
      "    Positive       0.71      0.89      0.79       184\n",
      "\n",
      "    accuracy                           0.68       378\n",
      "   macro avg       0.64      0.61      0.61       378\n",
      "weighted avg       0.66      0.68      0.65       378\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.6402116402116402\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.82      0.59      0.69       102\n",
      "     Neutral       0.40      0.11      0.17        92\n",
      "    Positive       0.61      0.93      0.74       184\n",
      "\n",
      "    accuracy                           0.64       378\n",
      "   macro avg       0.61      0.54      0.53       378\n",
      "weighted avg       0.62      0.64      0.59       378\n",
      "\n",
      "\n",
      "Training Naive Bayes...\n",
      "\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.626984126984127\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.71      0.54      0.61       102\n",
      "     Neutral       0.52      0.17      0.26        92\n",
      "    Positive       0.61      0.90      0.73       184\n",
      "\n",
      "    accuracy                           0.63       378\n",
      "   macro avg       0.62      0.54      0.54       378\n",
      "weighted avg       0.62      0.63      0.59       378\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "\n",
      "SVM Results:\n",
      "Accuracy: 0.6693121693121693\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      0.58      0.66       102\n",
      "     Neutral       0.41      0.38      0.39        92\n",
      "    Positive       0.74      0.86      0.80       184\n",
      "\n",
      "    accuracy                           0.67       378\n",
      "   macro avg       0.64      0.61      0.62       378\n",
      "weighted avg       0.66      0.67      0.66       378\n",
      "\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:10:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Results:\n",
      "Accuracy: 0.6693121693121693\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.83      0.73      0.77       102\n",
      "     Neutral       0.40      0.22      0.28        92\n",
      "    Positive       0.67      0.86      0.75       184\n",
      "\n",
      "    accuracy                           0.67       378\n",
      "   macro avg       0.63      0.60      0.60       378\n",
      "weighted avg       0.65      0.67      0.64       378\n",
      "\n",
      "\n",
      "Training Neural Network...\n",
      "\n",
      "Neural Network Results:\n",
      "Accuracy: 0.6587301587301587\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.55      0.63       102\n",
      "     Neutral       0.44      0.53      0.48        92\n",
      "    Positive       0.76      0.78      0.77       184\n",
      "\n",
      "    accuracy                           0.66       378\n",
      "   macro avg       0.64      0.62      0.63       378\n",
      "weighted avg       0.67      0.66      0.66       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results2 = evaluate_models(X_train_resampled, X_test,  y_train_resampled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autre methodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aycha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aycha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aycha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenisation\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Suppression des stopwords et lemmatisation\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word.isalpha()]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Remplacer les NaN par une chaîne vide\n",
    "df['SYNOPSIS'] = df['SYNOPSIS'].fillna(\"\")\n",
    "df['CAST'] = df['CAST'].fillna(\"\")\n",
    "df['PRODUCERS'] = df['PRODUCERS'].fillna(\"\")\n",
    "\n",
    "# Appliquer la fonction preprocess_text sur les colonnes concernées\n",
    "df['SYNOPSIS'] = df['SYNOPSIS'].apply(preprocess_text)\n",
    "df['CAST'] = df['CAST'].apply(preprocess_text)\n",
    "df['PRODUCERS'] = df['PRODUCERS'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "synopsis_tfidf = vectorizer.fit_transform(df['SYNOPSIS'])\n",
    "cast_tfidf = vectorizer.fit_transform(df['CAST'])\n",
    "producers_tfidf = vectorizer.fit_transform(df['PRODUCERS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes numériques\n",
    "numerical_features = df[['YEAR', 'DURATION_MIN', 'RATING_SUR_5']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_duration_to_minutes(duration):\n",
    "    if isinstance(duration, str):\n",
    "        # Si la durée est exprimée en heures ('h')\n",
    "        if 'h' in duration:\n",
    "            hours = int(duration.replace('h', ''))  # Extraire le nombre d'heures\n",
    "            return hours * 60  # Convertir en minutes\n",
    "        # Si la durée est exprimée en minutes ('m')\n",
    "        elif 'm' in duration:\n",
    "            return int(duration.replace('m', ''))  # Extraire et retourner les minutes\n",
    "    return 0  # Si la valeur est mal formatée, on retourne 0\n",
    "\n",
    "# Appliquer la conversion de la colonne DURATION_MIN\n",
    "df['DURATION_MIN'] = df['DURATION_MIN'].apply(convert_duration_to_minutes)\n",
    "\n",
    "# Convertir YEAR en valeurs numériques\n",
    "df['YEAR'] = pd.to_numeric(df['YEAR'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Préparation des données\n",
    "df[['YEAR', 'DURATION_MIN', 'RATING_SUR_5']] = df[['YEAR', 'DURATION_MIN', 'RATING_SUR_5']].fillna(0)\n",
    "df[['YEAR', 'DURATION_MIN', 'RATING_SUR_5']] = df[['YEAR', 'DURATION_MIN', 'RATING_SUR_5']].astype(float)\n",
    "\n",
    "# TF-IDF pour les colonnes textuelles\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "synopsis_tfidf = tfidf_vectorizer.fit_transform(df['SYNOPSIS'])\n",
    "cast_tfidf = tfidf_vectorizer.fit_transform(df['CAST'])\n",
    "producers_tfidf = tfidf_vectorizer.fit_transform(df['PRODUCERS'])\n",
    "\n",
    "# Encodage des labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Rating_Category'])\n",
    "\n",
    "# Caractéristiques numériques converties en matrice sparse\n",
    "numerical_features = df[['YEAR', 'DURATION_MIN']].values\n",
    "numerical_features_sparse = csr_matrix(numerical_features)\n",
    "\n",
    "# Combinaison des matrices\n",
    "X = scipy.sparse.hstack([synopsis_tfidf, cast_tfidf, producers_tfidf, numerical_features_sparse])\n",
    "\n",
    "# Diviser en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results:\n",
      "Accuracy: 0.6772\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       102\n",
      "           1       0.49      0.26      0.34        92\n",
      "           2       0.68      0.85      0.76       184\n",
      "\n",
      "    accuracy                           0.68       378\n",
      "   macro avg       0.64      0.62      0.62       378\n",
      "weighted avg       0.66      0.68      0.65       378\n",
      "\n",
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.6455\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.75      0.70       102\n",
      "           1       0.71      0.16      0.27        92\n",
      "           2       0.63      0.83      0.72       184\n",
      "\n",
      "    accuracy                           0.65       378\n",
      "   macro avg       0.67      0.58      0.56       378\n",
      "weighted avg       0.66      0.65      0.60       378\n",
      "\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Results:\n",
      "Accuracy: 0.2540\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.09      0.14       102\n",
      "           1       0.25      0.95      0.39        92\n",
      "           2       0.00      0.00      0.00       184\n",
      "\n",
      "    accuracy                           0.25       378\n",
      "   macro avg       0.20      0.34      0.18       378\n",
      "weighted avg       0.15      0.25      0.13       378\n",
      "\n",
      "{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aycha\\Desktop\\M2_BDIA\\NLP\\Projet_movie\\movie_critic\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:26:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Results:\n",
      "Accuracy: 0.6376\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71       102\n",
      "           1       0.42      0.27      0.33        92\n",
      "           2       0.65      0.80      0.72       184\n",
      "\n",
      "    accuracy                           0.64       378\n",
      "   macro avg       0.61      0.58      0.59       378\n",
      "weighted avg       0.62      0.64      0.62       378\n",
      "\n",
      "{'objective': 'multi:softprob', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}\n",
      "\n",
      "Neural Network Results:\n",
      "Accuracy: 0.6772\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.72       102\n",
      "           1       0.77      0.18      0.30        92\n",
      "           2       0.67      0.88      0.76       184\n",
      "\n",
      "    accuracy                           0.68       378\n",
      "   macro avg       0.71      0.61      0.59       378\n",
      "weighted avg       0.70      0.68      0.64       378\n",
      "\n",
      "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 500, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "Best Model: Logistic Regression\n",
      "Accuracy: 0.6772\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'report'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report for Best Model:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbest_model\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreport\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Model Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param, value \u001b[38;5;129;01min\u001b[39;00m best_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mKeyError\u001b[0m: 'report'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Dictionnaire pour stocker les résultats\n",
    "model_results = {}\n",
    "\n",
    "# Fonction pour entraîner un modèle et évaluer ses performances\n",
    "def train_and_evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    # Appliquer SMOTE pour équilibrer les classes dans le jeu d'entraînement\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Entraîner le modèle sur les données rééchantillonnées\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    weighted_f1 = report['weighted avg']['f1-score']\n",
    "    \n",
    "    # Stocker les résultats\n",
    "    model_results[model_name] = {'accuracy': accuracy, 'weighted_f1': weighted_f1}\n",
    "    \n",
    "    # Afficher les résultats pour chaque modèle\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(model.get_params())\n",
    "    \n",
    "# Définir les modèles à évaluer\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    'Neural Network': MLPClassifier(max_iter=500)\n",
    "}\n",
    "\n",
    "# Entraîner et évaluer chaque modèle\n",
    "for model_name, model in models.items():\n",
    "    train_and_evaluate_model(model, model_name, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Sélectionner le meilleur modèle selon l'accuracy\n",
    "best_model_name = max(model_results, key=lambda name: model_results[name]['accuracy'])\n",
    "best_model = model_results[best_model_name]\n",
    "\n",
    "# Résumé du meilleur modèle\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_model['accuracy']:.4f}\")\n",
    "print(f\"Classification Report for Best Model:\\n{best_model['report']}\")\n",
    "print(\"Best Model Parameters:\")\n",
    "for param, value in best_model['parameters'].items():\n",
    "    print(f\"  {param}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_critic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
